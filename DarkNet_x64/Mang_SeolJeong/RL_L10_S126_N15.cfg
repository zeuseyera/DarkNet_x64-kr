[net]
;강화학습 10층, 입력:126, 나옴:15
;SaBi 126x126x3
# 수련 사리수
#batch=128
batch=1
subdivisions=1
height=126
width=126
channels=3
momentum=0.9
decay=0.0005

;학습정책관련, policy:학습률 조정정책, max_batches:사리단위 수련 반복횟수
learning_rate=0.01
policy=poly
power=4
max_batches = 60000

[convolutional]
;L0 CV 126x126x3, p0-> 3x3, 1 -> 124x124x24
batch_normalize=1
filters=24
size=3
stride=1
pad=0
activation=relu

[maxpool]
;L1 MP 124x124x24 -> 2x2, 2 -> 62x62x24
size=2
stride=2

[convolutional]
;L2 CV 62x62x24, p0-> 3x3, 1 -> 60x60x24
batch_normalize=1
filters=24
size=3
stride=1
pad=0
activation=relu

[maxpool]
;L3 MP 60x60x24 -> 2x2, 2 -> 30x30x24
size=2
stride=2

[convolutional]
;L4 CV 30x30x24, p0-> 3x3, 1 -> 28x28x24
batch_normalize=1
filters=24
size=3
stride=1
pad=0
activation=relu

[maxpool]
;L5 MP 28x28x24 -> 2x2, 2 -> 14x14x24
size=2
stride=2

[convolutional]
;L6 CV 14x14x24, p0-> 3x3, 1 -> 12x12x24
batch_normalize=1
filters=24
size=3
stride=1
pad=0
activation=relu

[maxpool]
;L7 MP 12x12x24 -> 2x2, 2 -> 6x6x24
size=2
stride=2

[connected]
;L8 FC 6x6x24(864), p0-> 1x1, 1 -> 1x1x45(38,880)
batch_normalize=1
output=45
activation=relu

[connected]
;L9 FC 6x6x24x45(38,880) , p0-> 1x1, 1 -> 1x1x15
batch_normalize=1
output=15
activation=relu

;[avgpool]
;L7

[softmax]
;L10 SM 15 -> 15
groups=1

[cost]
;오차계산 방식
;기본값: sse

